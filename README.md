# ğŸ™ï¸ Wise Knowledge - Podcast Transcripts Vector Search

Inteligentna baza wiedzy z transkryptami podcastÃ³w wykorzystujÄ…ca semantic search w Qdrant. System przetwarza transkrypcje podcastÃ³w i umoÅ¼liwia semantyczne wyszukiwanie treÅ›ci za pomocÄ… embeddingÃ³w OpenAI.

## ğŸ“‹ Opis projektu

System umoÅ¼liwiajÄ…cy budowÄ™ prywatnej bazy wiedzy z transkryptÃ³w podcastÃ³w z wykorzystaniem wyszukiwania semantycznego. Projekt wykorzystuje:
- **Qdrant** - bazÄ™ wektorowÄ… do przechowywania embeddingÃ³w
- **OpenAI Embeddings** (text-embedding-3-small) - do generowania reprezentacji wektorowych 512-wymiarowych
- **Python + uv** - do zarzÄ…dzania zaleÅ¼noÅ›ciami i uruchamiania skryptÃ³w
- **Docker** - do lokalnego uruchomienia Qdrant

## âœ¨ FunkcjonalnoÅ›ci

- ğŸ” **Semantic Search** - wyszukiwanie podobieÅ„stw semantycznych, nie tylko sÅ‚Ã³w kluczowych
- ğŸ“Š **Strukturyzowane metadane** - integracja danych JSON z informacjami o epizodach, sekcjach, key points, tagach
- ğŸ¯ **Inteligentny chunking** - jedna sekcja transkryptu = jeden chunk z embeddingiem
- ğŸ·ï¸ **Zaawansowane metadane** - episode_id, title, heading, key_points, tags, source_file
- âš¡ **Szybkie wyszukiwanie** - milisekundowe odpowiedzi dziÄ™ki indeksom wektorowym Qdrant
- ğŸ“ **PeÅ‚ny kontekst** - kaÅ¼dy chunk zawiera treÅ›Ä‡ sekcji oraz wszystkie metadane

## ğŸ—ï¸ Architektura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  transcripts/       â”‚
â”‚  *.json files       â”‚
â”‚  (episode data)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ingest_transcripts â”‚
â”‚  - Load JSONs       â”‚
â”‚  - OpenAI API       â”‚
â”‚  - Batch processing â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Qdrant Database    â”‚
â”‚  (Vector Store)     â”‚
â”‚  - 512-dim vectors  â”‚
â”‚  - Cosine distance  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Wymagania

- Python 3.11+
- Docker & Docker Compose
- OpenAI API Key
- `uv` (dependency manager)

### Instalacja

1. **Sklonuj repozytorium**
```bash
git clone <repo-url>
cd wise_knowledge
```

2. **Uruchom Qdrant**
```bash
cd docker
docker compose up -d
```

Qdrant bÄ™dzie dostÄ™pny pod:
- HTTP API: http://localhost:6333
- gRPC API: http://localhost:6334
- Dashboard: http://localhost:6333/dashboard

3. **Zainstaluj zaleÅ¼noÅ›ci**
```bash
cd wise_knowledge
uv sync
```

4. **Skonfiguruj zmienne Å›rodowiskowe**
```bash
cp .env.example .env
# Edytuj .env i dodaj swÃ³j OPENAI_API_KEY
```

5. **Uruchom ingestion**
```bash
uv run python main.py
```

Skrypt automatycznie:
- Wczyta wszystkie JSONy z `transcripts/`
- Wygeneruje embeddingi dla kaÅ¼dej sekcji
- Utworzy kolekcjÄ™ `podcasts_transcripts` w Qdrant (jeÅ›li nie istnieje)
- Zapisze wektory wraz z metadanymi

## ğŸ“ Struktura projektu

```
.
â”œâ”€â”€ docker/
â”‚   â””â”€â”€ compose.yaml           # Konfiguracja Qdrant
â”œâ”€â”€ transcripts/               # Pliki JSON z transkryptami
â”‚   â”œâ”€â”€ strategia_biznesu.json
â”‚   â””â”€â”€ ...
â””â”€â”€ wise_knowledge/            # GÅ‚Ã³wny pakiet Python
    â”œâ”€â”€ tests/                 # Testy jednostkowe
    â”‚   â”œâ”€â”€ conftest.py        # Pytest fixtures
    â”‚   â””â”€â”€ test_ingest_transcripts.py
    â”œâ”€â”€ pyproject.toml         # ZaleÅ¼noÅ›ci (uv)
    â”œâ”€â”€ pytest.ini             # Konfiguracja pytest
    â”œâ”€â”€ .env.example           # Szablon zmiennych Å›rodowiskowych
    â”œâ”€â”€ main.py                # Entry point aplikacji
    â”œâ”€â”€ ingest_transcripts.py  # Logika ingestion
    â””â”€â”€ explore_database.ipynb # Jupyter notebook do eksploracji danych
```

## ğŸ“„ Format JSON transkryptÃ³w

KaÅ¼dy plik JSON w folderze `transcripts/` powinien mieÄ‡ strukturÄ™:

```json
{
  "episode_id": "ep_001",
  "title": "TytuÅ‚ odcinka",
  "summary": "KrÃ³tkie podsumowanie caÅ‚ego odcinka",
  "tags": ["tag1", "tag2", "tag3"],
  "sections": [
    {
      "heading": "NagÅ‚Ã³wek sekcji",
      "content": "PeÅ‚na treÅ›Ä‡ sekcji (uÅ¼yta do embeddingu)",
      "key_points": [
        "Kluczowy punkt 1",
        "Kluczowy punkt 2"
      ]
    }
  ]
}
```

## ğŸ”§ Konfiguracja

Zmienne Å›rodowiskowe w `.env`:

```bash
# Wymagane
OPENAI_API_KEY=sk-...

# Opcjonalne (z wartoÅ›ciami domyÅ›lnymi)
QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=                      # Puste dla lokalnej instancji
QDRANT_COLLECTION=podcasts_transcripts
EMBEDDING_MODEL=text-embedding-3-small
EMBED_DIM=512
BATCH_SIZE=64
TRANSCRIPTS_DIR=../transcripts
```

## ğŸ§ª Testing

Projekt uÅ¼ywa pytest do testÃ³w jednostkowych.

### Uruchomienie testÃ³w

```bash
# Zainstaluj dev dependencies
cd wise_knowledge
uv sync --extra dev

# Uruchom wszystkie testy
uv run pytest

# Uruchom testy z coverage report
uv run pytest --cov

# Uruchom konkretny plik testowy
uv run pytest tests/test_ingest_transcripts.py

# Uruchom testy w trybie verbose
uv run pytest -v

# Generuj HTML coverage report
uv run pytest --cov --cov-report=html
# Raport w: htmlcov/index.html
```

### Struktura testÃ³w

- `tests/test_ingest_transcripts.py` - testy dla funkcji ingestion
- `tests/conftest.py` - wspÃ³lne fixtures dla testÃ³w
- `pytest.ini` - konfiguracja pytest

Testy pokrywajÄ…:
- Tworzenie kolekcji Qdrant
- Generowanie embeddingÃ³w
- Åadowanie i parsowanie JSONÃ³w
- Upload do Qdrant
- ObsÅ‚ugÄ™ bÅ‚Ä™dÃ³w

## ğŸ“Š Eksploracja Danych

Projekt zawiera Jupyter notebook do analizy zawartoÅ›ci bazy danych.

### Uruchomienie notebooka

```bash
# Zainstaluj Jupyter i zaleÅ¼noÅ›ci
cd wise_knowledge
uv sync --extra dev

# Uruchom Jupyter Lab
uv run jupyter lab

# Lub Jupyter Notebook
uv run jupyter notebook
```

NastÄ™pnie otwÃ³rz plik [explore_database.ipynb](wise_knowledge/explore_database.ipynb).

### FunkcjonalnoÅ›ci notebooka

- âœ… PodglÄ…d informacji o kolekcji Qdrant
- âœ… WyÅ›wietlanie pierwszych punktÃ³w z metadanymi
- âœ… Statystyki (liczba epizodÃ³w, Å›rednia dÅ‚ugoÅ›Ä‡ contentu, etc.)
- âœ… Analiza podziaÅ‚u na epizody
- âœ… Wizualizacje (rozkÅ‚ad dÅ‚ugoÅ›ci, key points, sekcje na epizod)
- âœ… Wyszukiwanie po metadanych
- âœ… PodglÄ…d szczegÃ³Å‚Ã³w konkretnego punktu
- âœ… Eksport danych do CSV

## ğŸ” Wyszukiwanie Semantyczne (TODO)

Planowane funkcjonalnoÅ›ci wyszukiwania:
- Query API do semantycznego przeszukiwania
- Filtrowanie po episode_id, tagach
- Zwracanie najbardziej podobnych sekcji z kontekstem
- Integracja z MCP (Model Context Protocol)

## ğŸ³ Docker

Projekt uÅ¼ywa Docker Compose do uruchomienia Qdrant:

```bash
# Uruchom
cd docker
docker compose up -d

# SprawdÅº status
docker compose ps

# Logi
docker compose logs -f

# Zatrzymaj
docker compose down

# Zatrzymaj i usuÅ„ dane
docker compose down -v
```

## ğŸ” BezpieczeÅ„stwo i prywatnoÅ›Ä‡

- âœ… Dane transkryptÃ³w przechowywane lokalnie
- âœ… Qdrant hostowany lokalnie
- âœ… Embeddingi generowane przez OpenAI API (text-embedding-3-small)
- âš ï¸ PamiÄ™taj o `.gitignore` dla `.env` i danych osobowych
- âš ï¸ Nie commituj plikÃ³w z `OPENAI_API_KEY`

## ğŸ“Š SzczegÃ³Å‚y techniczne

- **Embedding Model**: text-embedding-3-small
- **Wymiary**: 512
- **Distance Metric**: Cosine similarity
- **Batch Size**: 64 sekcje na request
- **Chunking**: 1 sekcja = 1 punkt w Qdrant
- **ID Format**: `{episode_id}_section_{idx}`

## ğŸ“ Licencja

Distributed under the MIT License. See `LICENSE` for more information.
