# ğŸ™ï¸ Wise Knowledge - Podcast Transcripts Vector Search

Inteligentna baza wiedzy z transkryptami podcastÃ³w wykorzystujÄ…ca semantic search w Qdrant. System przetwarza transkrypcje podcastÃ³w i umoÅ¼liwia semantyczne wyszukiwanie treÅ›ci za pomocÄ… embeddingÃ³w OpenAI.

## ğŸ¯ Czym jest ten projekt?

Kompletny system RAG (Retrieval-Augmented Generation) skÅ‚adajÄ…cy siÄ™ z:
1. **Pipeline przetwarzania** - transformacja transkryptÃ³w JSON â†’ embeddingi â†’ baza wektorowa
2. **MCP Server** - API zgodne z Model Context Protocol do wyszukiwania semantycznego
3. **RAG Client** - interaktywny chat z Ollama wykorzystujÄ…cy bazÄ™ wiedzy
4. **Claude Skill** - bezpoÅ›rednia integracja z Claude Code

Projekt moÅ¼na uÅ¼ywaÄ‡ samodzielnie (RAG client) lub jako backend wiedzy dla AI assistants (Claude, wÅ‚asne agenty).

## ğŸ“‹ Opis projektu

System umoÅ¼liwiajÄ…cy budowÄ™ prywatnej bazy wiedzy z transkryptÃ³w podcastÃ³w z wykorzystaniem wyszukiwania semantycznego. Projekt wykorzystuje:
- **Qdrant** - bazÄ™ wektorowÄ… do przechowywania embeddingÃ³w
- **OpenAI Embeddings** (text-embedding-3-small) - do generowania reprezentacji wektorowych 512-wymiarowych
- **Python + uv** - do zarzÄ…dzania zaleÅ¼noÅ›ciami i uruchamiania skryptÃ³w
- **Docker** - do lokalnego uruchomienia Qdrant

## âœ¨ FunkcjonalnoÅ›ci

- ğŸ” **Semantic Search** - wyszukiwanie podobieÅ„stw semantycznych, nie tylko sÅ‚Ã³w kluczowych
- ğŸ“Š **Strukturyzowane metadane** - integracja danych JSON z informacjami o epizodach, sekcjach, key points, tagach
- ğŸ¯ **Inteligentny chunking** - jedna sekcja transkryptu = jeden chunk z embeddingiem
- ğŸ·ï¸ **Zaawansowane metadane** - episode_id, title, heading, key_points, tags, source_file
- âš¡ **Szybkie wyszukiwanie** - milisekundowe odpowiedzi dziÄ™ki indeksom wektorowym Qdrant
- ğŸ“ **PeÅ‚ny kontekst** - kaÅ¼dy chunk zawiera treÅ›Ä‡ sekcji oraz wszystkie metadane
- ğŸ¤– **MCP Server** - API wyszukiwania przez Model Context Protocol
- ğŸ’¬ **RAG Chat** - Interaktywny klient z Ollama do rozmÃ³w opartych na bazie wiedzy
- ğŸ¨ **Claude Code Skill** - BezpoÅ›rednia integracja z Claude do wyszukiwania w rozmowach

## ğŸ—ï¸ Architektura

Projekt skÅ‚ada siÄ™ z czterech gÅ‚Ã³wnych komponentÃ³w:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  transcripts/       â”‚
â”‚  *.json files       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Ingestion Pipeline â”‚â”€â”€â”€â”€â–¶â”‚  Qdrant Database    â”‚
â”‚  (wise_knowledge/)  â”‚     â”‚  - 512-dim vectors  â”‚
â”‚  - Load JSONs       â”‚     â”‚  - Cosine distance  â”‚
â”‚  - OpenAI Embeddingsâ”‚     â”‚  - Metadata         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                  â”‚                  â”‚
                    â–¼                  â–¼                  â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   MCP Server     â”‚  â”‚  MCP Client  â”‚  â”‚ Claude Skill â”‚
         â”‚  (mcp_server/)   â”‚  â”‚ (mcp_client/)â”‚  â”‚   (skills/)  â”‚
         â”‚  - Search API    â”‚  â”‚  - Ollama    â”‚  â”‚  - Claude    â”‚
         â”‚  - MCP Protocol  â”‚  â”‚  - RAG Chat  â”‚  â”‚    Code      â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Komponenty:**
1. **Ingestion Pipeline** - Przetwarza transkrypty i tworzy embeddingi
2. **Qdrant Database** - Przechowuje wektory i metadane
3. **MCP Server** - UdostÄ™pnia API wyszukiwania przez Model Context Protocol
4. **MCP Client** - Interaktywny klient czatu z Ollama (RAG)
5. **Claude Skill** - Integracja z Claude Code do wyszukiwania w rozmowach

## ğŸš€ Quick Start

### Wymagania

- Python 3.11+
- Docker & Docker Compose
- OpenAI API Key
- `uv` (dependency manager)
- Ollama (opcjonalnie, dla MCP Client)

### Instalacja

1. **Sklonuj repozytorium**
```bash
git clone <repo-url>
cd wise_knowledge
```

2. **Uruchom Qdrant**
```bash
cd docker
docker compose up -d
```

Qdrant bÄ™dzie dostÄ™pny pod:
- HTTP API: http://localhost:6333
- gRPC API: http://localhost:6334
- Dashboard: http://localhost:6333/dashboard

3. **Zainstaluj zaleÅ¼noÅ›ci**
```bash
cd wise_knowledge
uv sync
```

4. **Skonfiguruj zmienne Å›rodowiskowe**
```bash
cp .env.example .env
# Edytuj .env i dodaj swÃ³j OPENAI_API_KEY
```

5. **Uruchom ingestion**
```bash
uv run python main.py
```

Skrypt automatycznie:
- Wczyta wszystkie JSONy z `transcripts/`
- Wygeneruje embeddingi dla kaÅ¼dej sekcji
- Utworzy kolekcjÄ™ `podcasts_transcripts` w Qdrant (jeÅ›li nie istnieje)
- Zapisze wektory wraz z metadanymi

## ğŸ“ Struktura projektu

```
.
â”œâ”€â”€ docker/
â”‚   â””â”€â”€ compose.yaml           # Konfiguracja Qdrant
â”œâ”€â”€ transcripts/               # Pliki JSON z transkryptami
â”‚   â”œâ”€â”€ strategia_biznesu.json
â”‚   â””â”€â”€ ...
â”œâ”€â”€ skills/                    # Claude Code skills
â”‚   â””â”€â”€ wise-knowledge-search/ # Skill wyszukiwania
â”‚       â”œâ”€â”€ SKILL.md           # Definicja skill
â”‚       â”œâ”€â”€ README.md          # Dokumentacja
â”‚       â””â”€â”€ EXAMPLES.md        # PrzykÅ‚ady uÅ¼ycia
â”œâ”€â”€ mcp_server/                # MCP Server (Semantic Search API)
â”‚   â”œâ”€â”€ tests/                 # Testy MCP server
â”‚   â”‚   â”œâ”€â”€ conftest.py
â”‚   â”‚   â””â”€â”€ test_search.py
â”‚   â”œâ”€â”€ pyproject.toml         # ZaleÅ¼noÅ›ci MCP server
â”‚   â”œâ”€â”€ .env.example           # Szablon zmiennych
â”‚   â”œâ”€â”€ search.py              # Logika wyszukiwania
â”‚   â””â”€â”€ main.py                # Implementacja MCP server
â”œâ”€â”€ mcp_client/                # Interaktywny klient z Ollama
â”‚   â”œâ”€â”€ pyproject.toml         # ZaleÅ¼noÅ›ci klienta
â”‚   â”œâ”€â”€ .env.example           # Konfiguracja Ollama
â”‚   â””â”€â”€ main.py                # Interfejs chat
â””â”€â”€ wise_knowledge/            # Pakiet ingestion
    â”œâ”€â”€ tests/                 # Testy jednostkowe
    â”‚   â”œâ”€â”€ conftest.py        # Pytest fixtures
    â”‚   â””â”€â”€ test_ingest_transcripts.py
    â”œâ”€â”€ pyproject.toml         # ZaleÅ¼noÅ›ci (uv)
    â”œâ”€â”€ pytest.ini             # Konfiguracja pytest
    â”œâ”€â”€ .env.example           # Szablon zmiennych Å›rodowiskowych
    â”œâ”€â”€ main.py                # Entry point aplikacji
    â”œâ”€â”€ ingest_transcripts.py  # Logika ingestion
    â””â”€â”€ explore_database.ipynb # Jupyter notebook do eksploracji danych
```

## ğŸ“„ Format JSON transkryptÃ³w

KaÅ¼dy plik JSON w folderze `transcripts/` powinien mieÄ‡ strukturÄ™:

```json
{
  "episode_id": "ep_001",
  "title": "TytuÅ‚ odcinka",
  "summary": "KrÃ³tkie podsumowanie caÅ‚ego odcinka",
  "tags": ["tag1", "tag2", "tag3"],
  "sections": [
    {
      "heading": "NagÅ‚Ã³wek sekcji",
      "content": "PeÅ‚na treÅ›Ä‡ sekcji (uÅ¼yta do embeddingu)",
      "key_points": [
        "Kluczowy punkt 1",
        "Kluczowy punkt 2"
      ]
    }
  ]
}
```

## ğŸ”§ Konfiguracja

Zmienne Å›rodowiskowe w `.env`:

```bash
# Wymagane
OPENAI_API_KEY=sk-...

# Opcjonalne (z wartoÅ›ciami domyÅ›lnymi)
QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=                      # Puste dla lokalnej instancji
QDRANT_COLLECTION=podcasts_transcripts
EMBEDDING_MODEL=text-embedding-3-small
EMBED_DIM=512
BATCH_SIZE=64
TRANSCRIPTS_DIR=../transcripts
```

## ğŸ§ª Testing

Projekt uÅ¼ywa pytest do testÃ³w jednostkowych.

### Uruchomienie testÃ³w

```bash
# Zainstaluj dev dependencies
cd wise_knowledge
uv sync --extra dev

# Uruchom wszystkie testy
uv run pytest

# Uruchom testy z coverage report
uv run pytest --cov

# Uruchom konkretny plik testowy
uv run pytest tests/test_ingest_transcripts.py

# Uruchom testy w trybie verbose
uv run pytest -v

# Generuj HTML coverage report
uv run pytest --cov --cov-report=html
# Raport w: htmlcov/index.html
```

### Struktura testÃ³w

- `tests/test_ingest_transcripts.py` - testy dla funkcji ingestion
- `tests/conftest.py` - wspÃ³lne fixtures dla testÃ³w
- `pytest.ini` - konfiguracja pytest

Testy pokrywajÄ…:
- Tworzenie kolekcji Qdrant
- Generowanie embeddingÃ³w
- Åadowanie i parsowanie JSONÃ³w
- Upload do Qdrant
- ObsÅ‚ugÄ™ bÅ‚Ä™dÃ³w

## ğŸ“Š Eksploracja Danych

Projekt zawiera Jupyter notebook do analizy zawartoÅ›ci bazy danych.

### Uruchomienie notebooka

```bash
# Zainstaluj Jupyter i zaleÅ¼noÅ›ci
cd wise_knowledge
uv sync --extra dev

# Uruchom Jupyter Lab
uv run jupyter lab

# Lub Jupyter Notebook
uv run jupyter notebook
```

NastÄ™pnie otwÃ³rz plik [explore_database.ipynb](wise_knowledge/explore_database.ipynb).

### FunkcjonalnoÅ›ci notebooka

- âœ… PodglÄ…d informacji o kolekcji Qdrant
- âœ… WyÅ›wietlanie pierwszych punktÃ³w z metadanymi
- âœ… Statystyki (liczba epizodÃ³w, Å›rednia dÅ‚ugoÅ›Ä‡ contentu, etc.)
- âœ… Analiza podziaÅ‚u na epizody
- âœ… Wizualizacje (rozkÅ‚ad dÅ‚ugoÅ›ci, key points, sekcje na epizod)
- âœ… Wyszukiwanie po metadanych
- âœ… PodglÄ…d szczegÃ³Å‚Ã³w konkretnego punktu
- âœ… Eksport danych do CSV

## ğŸ” Wyszukiwanie Semantyczne

System udostÄ™pnia trzy sposoby wyszukiwania w bazie wiedzy:

### 1. MCP Server (API)

Model Context Protocol server udostÄ™pniajÄ…cy API wyszukiwania.

**Setup:**
```bash
cd mcp_server
uv sync
cp .env.example .env
# Edytuj .env i dodaj OPENAI_API_KEY

# Uruchom server
uv run python main.py
```

**Integracja z Claude Desktop/Code:**

Dodaj do konfiguracji MCP (np. `~/.config/claude-code/mcp.json`):
```json
{
  "mcpServers": {
    "wise-knowledge": {
      "command": "uv",
      "args": [
        "--directory",
        "/peÅ‚na/Å›cieÅ¼ka/do/wise_knowledge/mcp_server",
        "run",
        "python",
        "main.py"
      ]
    }
  }
}
```

**DostÄ™pne narzÄ™dzia MCP:**
- `search_podcasts` - wyszukiwanie semantyczne z parametrami query, limit, score_threshold
- `get_collection_status` - statystyki bazy wiedzy

**Testy:**
```bash
cd mcp_server
uv sync --extra dev
uv run pytest
uv run pytest --cov  # z coverage
```

### 2. MCP Client (Interaktywny Chat z Ollama)

Konsolowy klient Å‚Ä…czÄ…cy MCP server z lokalnym LLM (Ollama) do rozmÃ³w RAG.

**Setup:**
```bash
cd mcp_client
uv sync
cp .env.example .env
# Edytuj .env i ustaw OLLAMA_MODEL (domyÅ›lnie: llama3.2:latest)
```

**Wymagania:**
- Ollama zainstalowany i uruchomiony (`ollama serve`)
- Model pobrany (`ollama pull llama3.2:latest`)
- MCP server skonfigurowany (uÅ¼ywa `mcp_server/` z projektu)

**Uruchomienie:**
```bash
cd mcp_client
uv run python main.py
```

**Funkcje:**
- Interaktywny chat z pytaniami w naturalnym jÄ™zyku
- RAG workflow: wyszukiwanie â†’ kontekst â†’ Ollama â†’ odpowiedÅº
- Komenda `status` - statystyki kolekcji
- Opcja wyÅ›wietlania szczegÃ³Å‚owych wynikÃ³w wyszukiwania

### 3. Claude Code Skill

Skill dla Claude Code umoÅ¼liwiajÄ…cy wyszukiwanie bezpoÅ›rednio w rozmowach z Claude.

**Instalacja:**
```bash
# macOS
cp -r skills/wise-knowledge-search ~/Library/Application\ Support/Claude/skills/

# Linux
cp -r skills/wise-knowledge-search ~/.config/claude/skills/
```

**Wymagania:**
- Qdrant uruchomiony: `cd docker && docker compose up -d`
- Baza zasilona: `cd wise_knowledge && uv run python main.py`
- MCP server skonfigurowany w Claude Code (patrz wyÅ¼ej)
- Environment: `mcp_server/.env` z `OPENAI_API_KEY`

**UÅ¼ycie:**

Claude automatycznie aktywuje skill gdy zapytasz o treÅ›ci podcastÃ³w:
- "Co mÃ³wiono w podcastach o strategii marketingowej?"
- "ZnajdÅº odcinki o AI i automatyzacji"
- "Ile epizodÃ³w jest w bazie?"

WiÄ™cej przykÅ‚adÃ³w: [skills/wise-knowledge-search/EXAMPLES.md](skills/wise-knowledge-search/EXAMPLES.md)

## ğŸ³ Docker

Projekt uÅ¼ywa Docker Compose do uruchomienia Qdrant:

```bash
# Uruchom
cd docker
docker compose up -d

# SprawdÅº status
docker compose ps

# Logi
docker compose logs -f

# Zatrzymaj
docker compose down

# Zatrzymaj i usuÅ„ dane
docker compose down -v
```

## ğŸ” BezpieczeÅ„stwo i prywatnoÅ›Ä‡

- âœ… Dane transkryptÃ³w przechowywane lokalnie
- âœ… Qdrant hostowany lokalnie
- âœ… Embeddingi generowane przez OpenAI API (text-embedding-3-small)
- âš ï¸ PamiÄ™taj o `.gitignore` dla `.env` i danych osobowych
- âš ï¸ Nie commituj plikÃ³w z `OPENAI_API_KEY`

## ğŸ“Š SzczegÃ³Å‚y techniczne

### Embeddings
- **Model**: text-embedding-3-small (OpenAI)
- **Wymiary**: 512
- **Distance Metric**: Cosine similarity
- **Batch Size**: 64 sekcje na request
- **Chunking**: 1 sekcja = 1 punkt w Qdrant
- **ID Format**: Auto-incrementing integers (original `{episode_id}_section_{idx}` w payload)

### Komponenty
- **Ingestion**: Python 3.11+, uv, pytest
- **Qdrant**: Docker, localhost:6333 (HTTP), localhost:6334 (gRPC)
- **MCP Server**: Python 3.11+, mcp library, async support
- **MCP Client**: Python 3.11+, Ollama integration, RAG workflow
- **Claude Skill**: MCP tools, Claude Code integration

## ğŸ“ Licencja

Distributed under the MIT License. See `LICENSE` for more information.
