# Ollama Configuration
OLLAMA_MODEL=llama3.2:latest  # or any other model you have installed
OLLAMA_BASE_URL=http://localhost:11434

# MCP Server Configuration
MCP_SERVER_COMMAND=uv
MCP_SERVER_ARGS=--directory,/full/path/to/wise_knowledge/mcp_server,run,python,main.py
